# Data types and sizes

- `char`
	- a single byte, capable of holding one character in the local
	character set
- `int`
	- an integer, reflecting the natural size of integers on the 
	host machine
- `float`
	- single-precision floating point
- `double`
	- double-precision floating point

There are also a number of qualifiers that can be applied to these types.
`short` and `long` apply to integers.

```C
short int sh;
long int counter;
```

The word `int` can be omitted in such declarations, and usually is.
The idea is to be able to specify different lengths of integers where it 
makes sense. `short` is usually 16 bits and `long` is usually 32. `int` is
whatever makes sense for the host machine.

The qualifier `signed` or `unsigned` can be applied to any integer, 
including `char`.

> `unsigned` numbers are always positive or zero. They can represent
> values up to 2^n - 1 where n is the number of the bits in the type.

For `chars`, which are 8 bit integers, if they are signed, they can 
represent values from -128 to 127. If they are unsigned, they can 
represent values from 0 to 255.

`long double` specifies extended precision floating point. The sizes of 
floating point objects depends on implementation.

The standard headers `<limits.h>` and `<float.h>` contain symbolic 
constants for all these sizes as well as machine and compiler properties.

## Excercises

- 2-1. Write a program to determine the ranges of `char`, `short`, `int`,
and `long` variables, both `signed` and `unsigned` by printing from 
standard headers and by computation.
	- see ex\_2-01 in `programs`
